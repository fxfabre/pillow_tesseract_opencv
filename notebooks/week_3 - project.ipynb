{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Project #\n",
    "1. This is a project with minimal scaffolding. Expect to use the the discussion forums to gain insights! Itâ€™s not cheating to ask others for opinions or perspectives!\n",
    "2. Be inquisitive, try out new things.\n",
    "3. Use the previous modules for insights into how to complete the functions! You'll have to combine Pillow, OpenCV, and Pytesseract\n",
    "4. There are hints provided in Coursera, feel free to explore the hints if needed. Each hint provide progressively more details on how to solve the issue. This project is intended to be comprehensive and difficult if you do it without the hints.\n",
    "\n",
    "### The Assignment ###\n",
    "Take a [ZIP file](https://en.wikipedia.org/wiki/Zip_(file_format)) of images and process them, using a [library built into python](https://docs.python.org/3/library/zipfile.html) that you need to learn how to use. A ZIP file takes several different files and compresses them, thus saving space, into one single file. The files in the ZIP file we provide are newspaper images (like you saw in week 3). Your task is to write python code which allows one to search through the images looking for the occurrences of keywords and faces. E.g. if you search for \"pizza\" it will return a contact sheet of all of the faces which were located on the newspaper page which mentions \"pizza\".  \n",
    "This will test your ability to :\n",
    "- learn a new library\n",
    "- use OpenCV to detect faces\n",
    "- use tesseract to do optical character recognition\n",
    "- use PIL to composite images together into contact sheets\n",
    "\n",
    "Each page of the newspapers is saved as a single PNG image in a file called [images.zip](../readonly/images.zip). These newspapers are in english, and contain a variety of stories, advertisements and images. Note: This file is fairly large (~200 MB) and may take some time to work with, I would encourage you to use [small_img.zip](../readonly/small_img.zip) for testing.\n",
    "\n",
    "Here's an example of the output expected. Using the [small_img.zip](../readonly/small_img.zip) file, if I search for the string \"Christopher\" I should see the following image:\n",
    "![Christopher Search](../readonly/small_project.png)\n",
    "If I were to use the [images.zip](../readonly/images.zip) file and search for \"Mark\" I should see the following image (note that there are times when there are no faces on a page, but a word is found!):\n",
    "![Mark Search](../readonly/large_project.png)\n",
    "\n",
    "Note: That big file can take some time to process - for me it took nearly ten minutes! Use the small one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Set\n",
    "import zipfile\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageChops\n",
    "import cv2 as cv\n",
    "\n",
    "import pytesseract\n",
    "import kraken\n",
    "from kraken import pageseg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the face detection classifier\n",
    "face_cascade = cv.CascadeClassifier('/app/readonly/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier('/app/readonly/haarcascade_eye.xml')\n",
    "\n",
    "# Extract all images\n",
    "with zipfile.ZipFile(\"/app/readonly/images.zip\") as zip_images:\n",
    "    zip_images.extractall(path=\"/app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images\n",
    "\n",
    "images = {\n",
    "    f\"a{n}\": cv.cvtColor(\n",
    "        cv.imread(f\"/app/a-{n}.png\"), cv.COLOR_BGR2RGB\n",
    "    )\n",
    "    for n in range(5)\n",
    "}\n",
    "{n: img.shape for n, img in images.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_words(cv_img: np.array) -> Set[str]:\n",
    "    # Convert to black and white\n",
    "    if len(cv_img.shape) == 3:\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2GRAY)    \n",
    "    threshold, cv_img_bw = cv.threshold(cv_img, int(cv_img.mean()) - 10, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    # Run Terreract & clean output\n",
    "    r = pytesseract.image_to_data(cv_img_bw)\n",
    "    df = pd.read_csv(StringIO(r), sep=\"\\t\")\n",
    "    df = df.dropna(subset=[\"text\"])\n",
    "    df[\"text\"] = df[\"text\"].str.strip()\n",
    "    df[\"len\"] = df[\"text\"].str.len()\n",
    "    df[\"char_width\"] = df[\"width\"] / df[\"len\"]\n",
    "    df = df[df[\"len\"] > 0]\n",
    "    \n",
    "    return (df, set(df[\"text\"].str.lower()))\n",
    "\n",
    "\n",
    "def erase_text_on_img(cv_img: np.array, df_tesseract: pd.DataFrame):\n",
    "    cv_img_no_text = cv_img.copy()\n",
    "    for row in df_tesseract.itertuples():\n",
    "        cv_img_no_text[row.top: row.top + row.height, row.left: row.left + row.width] = 255\n",
    "    return cv_img_no_text\n",
    "\n",
    "\n",
    "df_tesseract, words = get_words(images[\"a0\"])\n",
    "cv_img_no_text = erase_text_on_img(images[\"a0\"], df_tesseract)\n",
    "\n",
    "\n",
    "len(words), list(words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Face_coord(NamedTuple):\n",
    "    x: int\n",
    "    y: int\n",
    "    w: int\n",
    "    h: int\n",
    "    \n",
    "    @property\n",
    "    def center(self):\n",
    "        return (self.x + self.w//2, self.y + self.h//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_faces(cv_img: np.array):\n",
    "    pass\n",
    "\n",
    "cv_img_rgb = images[\"a4\"]\n",
    "cv_img_gray = cv.cvtColor(cv_img_rgb, cv.COLOR_RGB2GRAY)\n",
    "df_tesseract, words = get_words(cv_img_gray)\n",
    "cv_img_no_text = erase_text_on_img(cv_img_gray, df_tesseract)\n",
    "\n",
    "# Use the face_cascade classifier\n",
    "faces_color = [\n",
    "    (face_cascade.detectMultiScale(cv_img_no_text, 2.50), \"black\"),\n",
    "    (face_cascade.detectMultiScale(cv_img_no_text, 2.00), \"red\"),\n",
    "    (face_cascade.detectMultiScale(cv_img_no_text, 1.70), \"white\"),\n",
    "    (face_cascade.detectMultiScale(cv_img_no_text, 1.40), \"blue\"),\n",
    "    (face_cascade.detectMultiScale(cv_img_no_text, 1.20), \"green\"),\n",
    "]\n",
    "\n",
    "#pil_img = Image.fromarray(cv_img_rgb, mode=\"RGB\")\n",
    "pil_img = Image.fromarray(cv_img_no_text, mode=\"L\")\n",
    "drawing = ImageDraw.Draw(pil_img)\n",
    "# PIL.ImageDraw is looking for (x1, y1, x2, y2)\n",
    "\n",
    "faces_img = []\n",
    "for faces, color in faces_color:\n",
    "    for x, y, w, h in faces:\n",
    "        img = cv_img_gray[y: y + h, x: x + w]\n",
    "        eyes = eye_cascade.detectMultiScale(img)\n",
    "        #if len(eyes) > 0:\n",
    "        #    pprint(eyes)\n",
    "        drawing.rectangle((x, y, x + w, y + h), outline=color, width=4)\n",
    "        faces_img.append(img)\n",
    "\n",
    "print(\"nb words :\", df_tesseract.shape[0])\n",
    "print(\"nb faces detected :\", len(faces_img))\n",
    "print(\"char width :\", df[\"char_width\"].median())\n",
    "display(pil_img)\n",
    "for img in faces_img:\n",
    "    display(Image.fromarray(img, mode=\"L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_coords = []\n",
    "for faces, color in faces_color:\n",
    "    for x, y, w, h in faces:\n",
    "        faces_coords.append(Face_coord(x, y, w, h))\n",
    "\n",
    "distances = [\n",
    "    math.sqrt((p1.center[0] - p2.center[0])**2 + (p1.center[1] - p2.center[1])**2)\n",
    "    for p1 in faces_coords\n",
    "    for p2 in faces_coords\n",
    "]\n",
    "\n",
    "n, bins, patches = plt.hist(distances, 5000, density=False, facecolor='g', alpha=0.75)\n",
    "\n",
    "plt.xlabel('Smarts')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of IQ')\n",
    "plt.xlim(-10, 300)\n",
    "#plt.ylim(0, 0.03)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_coords = [\n",
    "    faces_coords.append(Face_coord(x, y, w, h))\n",
    "    for faces, color in faces_color\n",
    "    for x, y, w, h in faces\n",
    "]\n",
    "\n",
    "clusters = []\n",
    "while len(faces_coords) > 0:\n",
    "    p0 = faces_coords[0]\n",
    "    faces_coords = sorted(\n",
    "        faces_coords[1:],\n",
    "        key=lambda p: (p0.center[0] - p.center[0])**2 + (p0.center[1] - p0.center[1])**2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [\n",
    "    (p1.w + p1.h) // 2\n",
    "    for p1 in faces_coords\n",
    "]\n",
    "\n",
    "n, bins, patches = plt.hist(values, 100, density=False, facecolor='g', alpha=0.75)\n",
    "\n",
    "plt.xlabel('Smarts')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of IQ')\n",
    "#plt.xlim(-10, 300)\n",
    "#plt.ylim(0, 0.03)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = cv_img.shape[1]\n",
    "y_max = cv_img.shape[0]\n",
    "\n",
    "char_width = int(df[\"char_width\"].median())\n",
    "mask = np.full(cv_img.shape[:2], 255, dtype=np.uint8)\n",
    "for row in df.itertuples():\n",
    "    mask[row.top: row.top + row.height, row.left: row.left + row.width] = 0\n",
    "    \n",
    "    if row.left - char_width > 0:\n",
    "        mask[row.top: row.top + row.height, row.left - char_width: row.left] = 127\n",
    "    if row.left + row.width + char_width < x_max:\n",
    "        mask[row.top: row.top + row.height, row.left + row.width: row.left + row.width + char_width] = 127\n",
    "\n",
    "display(Image.fromarray(mask, \"L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"char_width\"].mean(), df[\"char_width\"].median(), df[\"char_width\"].min(), df[\"char_width\"].max())\n",
    "df.sort_values(\"height\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lines\n",
    "\n",
    "cv_img_rgb = images[\"a0\"]\n",
    "df, words = get_words(cv_img_rgb)\n",
    "cv_img_no_text = erase_text_on_img(cv_img_rgb, df)\n",
    "\n",
    "display(Image.fromarray(cv_img_no_text, \"RGB\"))\n",
    "\n",
    "\n",
    "dst = cv.Canny(cv_img_no_text, 50, 200, None, 3)\n",
    "cdst = cv.cvtColor(dst, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "# cv.HoughLinesP(image, rho, theta, threshold, lines, minLineLength, maxLineGap) -> lines\n",
    "lines = cv.HoughLinesP(dst, rho=1, theta=np.pi / 180, threshold=50, minLineLength=500, maxLineGap=20)\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    l = line[0]\n",
    "    cv.line(cdst, l[0:2], l[2:4], (0, 0, 255), 3, cv.LINE_AA)\n",
    "\n",
    "# source\n",
    "#display(Image.fromarray(dst, \"L\"))\n",
    "\n",
    "#cv.imshow(\"Detected Lines (in red) - Probabilistic Line Transform\", cdstP)\n",
    "display(Image.fromarray(cdst, \"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

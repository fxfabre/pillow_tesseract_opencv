{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release the Kraken!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The biggest limitation of tesseract is the lack of a layout engine inside of it. Tesseract\n",
    "# expects to be using fairly clean text, and gets confused if we don't crop out other artifacts.\n",
    "# It's not bad, but Kraken can help us out be segmenting pages.\n",
    "# https://pypi.org/project/kraken/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageChops\n",
    "\n",
    "import kraken\n",
    "from kraken import pageseg\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"/app/readonly/two_col.png\")\n",
    "display(im)\n",
    "\n",
    "black_and_white = im.convert('1')  # binary mode\n",
    "pageseg.segment(black_and_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column detection\n",
    "# parameter black_colseps : If set to True, kraken will assume that columns will be\n",
    "# separated by black lines.\n",
    "\n",
    "def show_boxes(img_rgb: Image) -> Image:\n",
    "    \"\"\"\n",
    "    Find boxes of text on the input image and draw those boxes on the image\n",
    "    \"\"\"\n",
    "    drawing_object = ImageDraw.Draw(img_rgb)\n",
    "    bounding_boxes = pageseg.segment(\n",
    "        img_rgb.convert('1'),\n",
    "        black_colseps=True\n",
    "    )['boxes']\n",
    "\n",
    "    for box in bounding_boxes:\n",
    "        drawing_object.rectangle(box, fill = None, outline ='red')\n",
    "\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "display(show_boxes(Image.open(\"/app/readonly/two_col.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target : find and draw a column separator\n",
    "#   we choose a size of at least : 25 pixels wide (1 char) and six lines high\n",
    "#   question : how many pixels are six lines high ?\n",
    "\n",
    "def calculate_line_height(img: Image) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the average height of a line from a given image based on the detected text boxes\n",
    "    \"\"\"\n",
    "    bounding_boxes = pageseg.segment(img.convert('1'))['boxes']\n",
    "    height_accumulator = sum(\n",
    "        bottom - top\n",
    "        for (left, top, right, bottom) in bounding_boxes\n",
    "    )\n",
    "    \n",
    "    return height_accumulator // len(bounding_boxes)\n",
    "\n",
    "# And lets test this with the image with have been using\n",
    "char_width = 25\n",
    "line_height = calculate_line_height(Image.open(\"/app/readonly/two_col.png\"))\n",
    "\n",
    "gap_box = (0, 0, char_width, line_height * 6)\n",
    "gap_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if there is a block of whitespace  \n",
    "\n",
    "WHITE_PIXEL = 255\n",
    "\n",
    "def gap_check(img: Image, location: Tuple[int, int]) -> bool:\n",
    "    \"\"\"\n",
    "    :img: binarized Image\n",
    "    :return: True if location is the top left corner of an empty area of size gap_box, otherwise False\n",
    "    \"\"\"\n",
    "    x0, y0 = location\n",
    "    if x0 < 0 or y0 < 0:\n",
    "        return False\n",
    "    if x0 + gap_box[2] >= img.width or y0 + gap_box[3] > img.height:\n",
    "        return False\n",
    "    \n",
    "    return all(\n",
    "        img.getpixel((x,y)) == WHITE_PIXEL\n",
    "        for x in range(x0, x0 + gap_box[2])\n",
    "        for y in range(y0, y0 + gap_box[3])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sep(img: Image, location: Tuple[int, int]):\n",
    "    \"\"\"\n",
    "    Draw a vertical line on img in the middle of the box.\n",
    "    location: Top left corner of the box\n",
    "    \"\"\"\n",
    "    x0, y0 = location\n",
    "\n",
    "    # Draw a line from (x1, y1) to (x2, y2)\n",
    "    x1 = x0 + int(gap_box[2]/2)\n",
    "    x2 = x1\n",
    "\n",
    "    y1 = y0\n",
    "    y2 = y1 + gap_box[3]\n",
    "    \n",
    "    drawing_object = ImageDraw.Draw(img)\n",
    "    drawing_object.rectangle((x1,y1,x2,y2), fill = 'black', outline ='black')\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vertical_bar(img: Image):\n",
    "    \"\"\"\n",
    "    Add a vertical bar in a 2-column text image\n",
    "    \"\"\"\n",
    "    for x in range(img.width):\n",
    "        for y in range(img.height):\n",
    "            if (gap_check(img, (x,y))):\n",
    "                draw_sep(img, (x,y))\n",
    "    return img\n",
    "\n",
    "# Lets read in our test image and convert it through binarization\n",
    "image = Image.open(\"/app/readonly/two_col.png\").convert(\"L\")\n",
    "image = add_vertical_bar(image)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(show_boxes(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## OpenCV : Comparing Image Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV supports reading of images in most file formats, such as JPEG, PNG, and TIFF. Most image and \n",
    "# video analysis requires converting images into grayscale first. This simplifies the image and reduces \n",
    "# noise allowing for improved analysis.\n",
    "\n",
    "img = cv.imread('/app/readonly/floyd.jpg')\n",
    "gray: np.ndarray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# The display package, doesn't know what to do with this image. So lets convert it\n",
    "# into a PIL object to render it in the browser.\n",
    "image = Image.fromarray(gray, \"L\")\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "# 3 dimensions image : width, height and a color depth.\n",
    "first_pixel = img[0][0]\n",
    "first_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "\n",
    "print(\"Original image\")\n",
    "print(gray)\n",
    "\n",
    "# If we wanted to represent that as a one dimensional image, we just call reshape\n",
    "print(\"Reshaped image\")\n",
    "image1d = np.reshape(gray, (1, gray.shape[0] * gray.shape[1]))\n",
    "print(image1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For instance, remember in the last lecture when we wanted to look for gaps in an image so\n",
    "# that we could draw lines to feed into kraken? Well, we use PIL to do this, using getpixel()\n",
    "# to look at individual pixels and see what the luminosity was, then ImageDraw.rectangle to\n",
    "# actually fill in a black bar separator. This was a nice high level API, and let us write\n",
    "# routines to do the work we wanted without having to understand too much about how the images\n",
    "# were being stored. But it was computationally very slow.\n",
    "#\n",
    "# Instead, we could write the code to do this using matrix features within numpy. Lets take\n",
    "# a look.\n",
    "\n",
    "img = cv.imread('/app/readonly/two_col.png')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find a white box :\n",
    "np.count_nonzero(gray[2:4, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create an image from ndarray, and change color\n",
    "\n",
    "white_matrix = np.full((6, 6), 255, dtype=np.uint8)\n",
    "display(Image.fromarray(white_matrix, \"L\"))\n",
    "\n",
    "white_matrix[:, 4] = np.full((1,6), 0, dtype=np.uint8)\n",
    "display(Image.fromarray(white_matrix, \"L\"))\n",
    "\n",
    "white_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection\n",
    "\n",
    "# First step is to load the XML-based classifiers\n",
    "face_cascade = cv.CascadeClassifier('/app/readonly/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier('/app/readonly/haarcascade_eye.xml')\n",
    "\n",
    "img = cv.imread('/app/readonly/floyd.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use the face_cascade classifier\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "# The resulting rectangles are in the format of (x,y,w,h) where x and y denote the upper\n",
    "# left hand point for the image and the width and height represent the bounding box.\n",
    "\n",
    "pil_img = Image.fromarray(gray, mode=\"L\")\n",
    "drawing = ImageDraw.Draw(pil_img)\n",
    "\n",
    "# PIL.ImageDraw is looking for (x1, y1, x2, y2)\n",
    "x, y, w, h = faces[0]\n",
    "drawing.rectangle((x, y, x + w, y + h), outline=\"white\")\n",
    "\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw rectangles around faces\n",
    "\n",
    "def show_rects(faces):\n",
    "    pil_img = Image.open('/app/readonly/msi_recruitment.gif')\n",
    "\n",
    "    # pil_img.mode == \"P\" (custom color palette) -> RGB\n",
    "    pil_img = pil_img.convert(\"RGB\")\n",
    "\n",
    "    drawing = ImageDraw.Draw(pil_img)\n",
    "    for x, y, w, h in faces:\n",
    "        drawing.rectangle((x, y, x+w, y+h), outline=\"white\")\n",
    "\n",
    "    display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use PIL to open our image # OpenCV can't work with Gif image\n",
    "pil_img = Image.open('/app/readonly/msi_recruitment.gif')\n",
    "\n",
    "pil_img.convert(\"L\").save(\"/app/notebooks/msi_recruitment.png\")\n",
    "cv_img = cv.imread(\"/app/notebooks/msi_recruitment.png\")\n",
    "\n",
    "# lets try and detect faces in that image\n",
    "faces = face_cascade.detectMultiScale(cv_img)\n",
    "\n",
    "show_rects(faces)\n",
    "\n",
    "# false negatives : missed four faces\n",
    "# false positives : something the machine thought was a face but it wasn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize this image\n",
    "\n",
    "threshold, cv_img_bin = cv.threshold(cv_img, 120, 255, cv.THRESH_BINARY)\n",
    "faces = face_cascade.detectMultiScale(cv_img_bin)\n",
    "show_rects(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detectMultiScale() parameters : \n",
    "#     change the scale factor = size of rectangles which are considered against the model\n",
    "\n",
    "faces = face_cascade.detectMultiScale(cv_img,1.05)\n",
    "show_rects(faces)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(cv_img,1.25)\n",
    "show_rects(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time spent :\n",
    "\n",
    "%timeit face_cascade.detectMultiScale(cv_img, 1.05)\n",
    "%timeit face_cascade.detectMultiScale(cv_img, 1.25)\n",
    "# Bigger square => faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Jupyter Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the nice things about using the Jupyter notebook systems is that there is a\n",
    "# rich set of contributed plugins that seek to extend this system. In this lecture I\n",
    "# want to introduce you to one such plugin, call ipy web rtc. Webrtc is a fairly new\n",
    "# protocol for real time communication on the web. Yup, I'm talking about chatting.\n",
    "# The widget brings this to the Jupyter notebook system. Lets take a look.\n",
    "\n",
    "from ipywebrtc import CameraStream, ImageRecorder\n",
    "\n",
    "# The image recorder lets us actually grab images from the camera stream. There are features\n",
    "# for downloading and using the image as well. We see that the default format is a png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = CameraStream.facing_user(audio=False)\n",
    "image_recorder = ImageRecorder(stream=camera)\n",
    "\n",
    "# Now, the docs are a little unclear how to use this within Jupyter, but if we call the\n",
    "# download() function it will actually store the results of the camera which is hooked up\n",
    "# in image_recorder.image. Lets try it out\n",
    "# First, lets tell the recorder to start capturing data\n",
    "image_recorder.recording = True\n",
    "# Now lets download the image\n",
    "image_recorder.download()\n",
    "# Then lets inspect the type of the image\n",
    "type(image_recorder.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, the object that it stores is an ipywidgets.widgets.widget_media.Image. How do we do\n",
    "# something useful with this? Well, an inspection of the object shows that there is a handy\n",
    "# value field which actually holds the bytes behind the image. And we know how to display\n",
    "# those.\n",
    "\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "img = PIL.Image.open(io.BytesIO(image_recorder.image.value))\n",
    "display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
